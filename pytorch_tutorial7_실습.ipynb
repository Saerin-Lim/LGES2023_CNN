{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from glob import glob\n",
    "from torchsummary import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local에서 실습 하시는 분은 실행 x\n",
    "%cd /content/LGES2023_CNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 똑같은 결과를 얻기 위한 시드 고정\n",
    "seed = 0\n",
    "torch.manual_seed(seed) # torch cpu seed 고정\n",
    "torch.cuda.manual_seed(seed) # torch gpu seed 고정\n",
    "torch.cuda.manual_seed_all(seed) # torch multi-gpu seed 고정\n",
    "np.random.seed(seed) # numpy seed 고정\n",
    "random.seed(seed) # python seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heros Data Resnet18로 전이학습하기\n",
    "\n",
    "Heros data : 6 종류의 히어로 이미지를 분류하는 데이터\n",
    "\n",
    "각 클래스 별로 130장의 학습 데이터와 30여장의 테스트 데이터가 존재\n",
    "\n",
    "학습 데이터는 (224,224)로 사이즈가 고정되어 있지만 테스트 데이터는 사이즈가 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('./images/img9.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 & 데이터로더\n",
    "\n",
    "학습 데이터에서 각 클래스 별로 30장 씩 validation으로 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# train/valid/test split using file path\n",
    "n_valid = 30\n",
    "\n",
    "\n",
    "# for문을 활용한 데이터 분할--------------------------------------------------\n",
    "\n",
    "train_path, valid_path, test_path = [], [], []\n",
    "train_labels, valid_labels, test_labels = [], [], []\n",
    "hero_list = os.listdir('./data/heros/train')\n",
    "\n",
    "for i, hero in enumerate(hero_list): # 각 class 별로 data split 진행\n",
    "    # enumerate함수는 반복이 진행된 횟수를 리턴(0부터 시작)\n",
    "    \n",
    "    # 현재 hero의 train 이미지 경로들을 glob함수로 불러오기\n",
    "    crt_train_path = \"\"\"채워주세요\"\"\"\n",
    "    # i번째 hero의 class를 i로 지정\n",
    "    crt_train_labels = [i] * len(crt_train_path)\n",
    "    # train path shuffle\n",
    "    random.shuffle(crt_train_path)\n",
    "    # 앞에 30개를 valid로 그 뒤를 train으로 지정\n",
    "    crt_train_path, crt_valid_path = \"\"\"채워주세요\"\"\"\n",
    "    crt_train_labels, crt_valid_labels = \"\"\"채워주세요\"\"\"\n",
    "    \"\"\"채워주세요\"\"\"\n",
    "    \n",
    "    # 현재 hero의 test 이미지 경로들을 glob함수로 불러오기\n",
    "    crt_test_path = \"\"\"채워주세요\"\"\"\n",
    "    # i번째 hero의 class를 i로 지정\n",
    "    \"\"\"채워주세요\"\"\"\n",
    "    \n",
    "    # 전체 path에 저장\n",
    "    train_path += \"\"\"채워주세요\"\"\"\n",
    "    valid_path += \"\"\"채워주세요\"\"\"\n",
    "    test_path += \"\"\"채워주세요\"\"\"\n",
    "    # 전체 labels에 저장\n",
    "    train_labels += \"\"\"채워주세요\"\"\"\n",
    "    valid_labels += \"\"\"채워주세요\"\"\"\n",
    "    test_labels += \"\"\"채워주세요\"\"\"\n",
    "\n",
    "print(f'trainset 이미지 수 : {len(train_path)}')\n",
    "print(f'validset 이미지 수 : {len(valid_path)}')\n",
    "print(f'testset 이미지 수  : {len(test_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "  데이터셋을 불러오거나 입력받아 전처리를 해주는 부분\n",
    "\n",
    "  def __len__(self):\n",
    "  데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "  len을 통해서 getitem의 idx 범위가 결정\n",
    "\n",
    "  def __getitem__(self, idx): \n",
    "  데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset 정의\n",
    "\n",
    "img_size = (128,128)\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, img_path, labels, mode, img_size):\n",
    "\n",
    "      if mode == 'train':\n",
    "        self.transform = \"\"\"채워주세요\"\"\"\n",
    "      else: # valid or test\n",
    "        self.transform = \"\"\"채워주세요\"\"\"\n",
    "        \n",
    "      self.img_path =img_path\n",
    "      self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.img_path)\n",
    "    def __getitem__(self,idx):\n",
    "      # idx에 맞는 path 선택\n",
    "      crt_img_path = \"\"\"채워주세요\"\"\"\n",
    "      img = Image.open(crt_img_path) # 이미지 오픈\n",
    "      # 이미지 변형\n",
    "      X = \"\"\"채워주세요\"\"\"\n",
    "      # idx에 맞는 label 선택\n",
    "      y = \"\"\"채워주세요\"\"\"\n",
    "      \n",
    "      return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 데이터셋 및 데이터로더 생성\n",
    "batch_size = 128\n",
    "trainset = CatDogDataset(img_path=\"\"\"채워주세요\"\"\", \n",
    "                         labels=\"\"\"채워주세요\"\"\",\n",
    "                         mode='train', img_size=img_size)\n",
    "\n",
    "validset = CatDogDataset(img_path=\"\"\"채워주세요\"\"\", \n",
    "                         labels=\"\"\"채워주세요\"\"\",\n",
    "                         mode='valid', img_size=img_size)\n",
    "\n",
    "testset = CatDogDataset(img_path=\"\"\"채워주세요\"\"\", \n",
    "                         labels=\"\"\"채워주세요\"\"\",\n",
    "                         mode='test', img_size=img_size)\n",
    "\n",
    "trainloader = DataLoader(dataset=\"\"\"채워주세요\"\"\", \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=\"\"\"채워주세요\"\"\",\n",
    "                         drop_last=\"\"\"채워주세요\"\"\")\n",
    "\n",
    "validloader = DataLoader(dataset=\"\"\"채워주세요\"\"\", \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=\"\"\"채워주세요\"\"\",\n",
    "                         drop_last=\"\"\"채워주세요\"\"\")\n",
    "\n",
    "testloader = DataLoader(dataset=\"\"\"채워주세요\"\"\", \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=\"\"\"채워주세요\"\"\",\n",
    "                         drop_last=\"\"\"채워주세요\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet18을 활용한 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('./images/img10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# 사전 학습된 resnet18 가져오기\n",
    "model = \"\"\"채워주세요\"\"\"\n",
    "summary(model, input_size=(3,128,128), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터가 업데이트 되지 않도록 모든 레이어에 대해 required_grad 끄기\n",
    "for param in \"\"\"채워주세요\"\"\":\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier를 현재 데이터의 클래스 개수에 맞게 대체(required_grad는 자동으로 켜짐)\n",
    "num_classes = 6\n",
    "in_features = \"\"\"채워주세요\"\"\"\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "print(model.fc, next(model.fc.parameters()).requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimizer 및 loss function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "weight_decay = 5e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(params=\"\"\"채워주세요\"\"\", # fc layer만 학습!!\n",
    "                             lr=lr,\n",
    "                             weight_decay=weight_decay)\n",
    "loss_fn = \"\"\"채워주세요\"\"\" # multi-class classification에 활용하는 loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 역전파 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 에폭에 대한 학습 단계 함수화\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          loss_fn,\n",
    "          dataloader,\n",
    "          device):\n",
    "    \n",
    "    model.train() # set train mode\n",
    "    \n",
    "    # epoch마다 학습이 어떻게 진행되는지 추적하기 위한 변수\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    n_train = 0\n",
    "    \n",
    "    for (imgs, targets) in dataloader: # loader를 통해 batch만큼 getitem\n",
    "        \n",
    "         # 두 텐서를 모델, 목적함수와 같은 device로\n",
    "        imgs = imgs.to(device) # B,3,32,32\n",
    "        targets = targets.to(device) # B\n",
    "        \n",
    "        # forward\n",
    "        outputs = \"\"\"채워주세요\"\"\" # B,2\n",
    "        \n",
    "        # loss 계산\n",
    "        loss = \"\"\"채워주세요\"\"\"\n",
    "        \n",
    "        # optimizer gradient 초기화\n",
    "        \"\"\"채워주세요\"\"\"\n",
    "        \n",
    "        # backward : gradient 계산\n",
    "        \"\"\"채워주세요\"\"\"\n",
    "        \n",
    "        # model weight update\n",
    "        \"\"\"채워주세요\"\"\"\n",
    "        \n",
    "        # loss 저장\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 맞게 예측한 개수 및 배치 데이터 개수 저장\n",
    "        preds = torch.max(outputs.detach(), dim=-1)[1] # B\n",
    "        acc = torch.eq(preds,targets).sum().cpu().item()\n",
    "        train_acc += acc\n",
    "        n_train += targets.shape[0]\n",
    "    \n",
    "    # 현재 에폭 평균 학습 loss와 accuracy 계산\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / n_train\n",
    "    \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 추론 단계 함수화\n",
    "def test(model,\n",
    "        loss_fn,\n",
    "        dataloader,\n",
    "        device):\n",
    "    \n",
    "    model.eval() # set eval mode\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    n_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (imgs, targets) in dataloader: # loader를 통해 batch만큼 getitem\n",
    "            \n",
    "            # 두 텐서를 모델, 목적함수와 같은 device로\n",
    "            imgs = imgs.to(device) # B,3,32,32\n",
    "            targets = targets.to(device) # B\n",
    "            \n",
    "            # forward\n",
    "            outputs = \"\"\"채워주세요\"\"\"\n",
    "            \n",
    "            # loss 계산\n",
    "            loss = \"\"\"채워주세요\"\"\"\n",
    "            \n",
    "            # loss 저장\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # 맞게 예측한 개수 및 배치 데이터 개수 저장\n",
    "            preds = torch.max(outputs.detach(), dim=-1)[1] # B\n",
    "            acc = torch.eq(preds,targets).sum().cpu().item()\n",
    "            test_acc += acc\n",
    "            n_test += targets.shape[0]\n",
    "    \n",
    "    # 현재 에폭 평균 학습 loss와 accuracy 계산\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / n_test\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체적인 학습 프레임워크를 함수화\n",
    "def main(model,\n",
    "         trainloader,\n",
    "         validloader,\n",
    "         testloader,\n",
    "         optimizer,\n",
    "         loss_fn,\n",
    "         epochs,\n",
    "         save_name='cat_dog_lenet5'):\n",
    "    \n",
    "    # device 세팅\n",
    "    if \"\"\"채워주세요\"\"\":\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        \n",
    "    # To device\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    \n",
    "    # training\n",
    "    best_acc = 0.\n",
    "    train_history = {'loss':[],'acc':[]}\n",
    "    valid_history = {'loss':[],'acc':[]}\n",
    "    \n",
    "    print('-'*20, '학습 시작', '-'*20)\n",
    "    print(f'Experiment : {save_name} \\n')\n",
    "    \n",
    "    elapsed_time = time.time()\n",
    "    for epoch in \"\"\"채워주세요\"\"\":\n",
    "        epoch_time = time.time()\n",
    "        # 한 에폭에 대한 학습\n",
    "        train_loss, train_acc = \"\"\"채워주세요\"\"\" # train 함수\n",
    "        # 에폭마다 validset을 통한 모델 평가\n",
    "        valid_loss, valid_acc = \"\"\"채워주세요\"\"\" # test 함수\n",
    "        # best model일 경우 모델 저장\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = \"\"\"채워주세요\"\"\"\n",
    "            best_epoch = \"\"\"채워주세요\"\"\"\n",
    "            save_dict = \"\"\"채워주세요\"\"\"\n",
    "            torch.save(\"\"\"채워주세요\"\"\")\n",
    "    \n",
    "        # 학습/테스트에 소요된 시간 계산\n",
    "        epoch_time = time.time() - epoch_time\n",
    "        \n",
    "        # 학습 정보 출력\n",
    "        print(f'Epoch     : {epoch+1:6} | Time     : {epoch_time:.2f} sec')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f}')\n",
    "        print(f'Train ACC : {train_acc:.4f} | Valid ACC : {valid_acc:.4f} \\n')\n",
    "    \n",
    "        # 에폭별 학습 정보 저장\n",
    "        train_history['loss'].append(train_loss)\n",
    "        train_history['acc'].append(train_acc)\n",
    "        valid_history['loss'].append(valid_loss)\n",
    "        valid_history['acc'].append(valid_acc)\n",
    "\n",
    "    print('-'*20, '학습 종료', '-'*20)\n",
    "    print(f'Best ACC : {best_acc:.4f} | Best Epoch : {best_epoch} \\n')\n",
    "    \n",
    "    print('-'*20, '테스트', '-'*20)\n",
    "    # load best model\n",
    "    load_dict = torch.load(\"\"\"채워주세요\"\"\", map_location=\"\"\"채워주세요\"\"\")\n",
    "    parameters = \"\"\"채워주세요\"\"\"\n",
    "    model.load_state_dict(parameters, strict=False)\n",
    "    \n",
    "    test_loss, test_acc = \"\"\"채워주세요\"\"\" # test 함수\n",
    "    \n",
    "    elapsed_time = time.time() - elapsed_time\n",
    "    \n",
    "    print(f'Experiments : {save_name}')\n",
    "    print(f'test Loss   : {test_loss:.4f} \\n')\n",
    "    print(f'test ACC    : {test_acc:.4f} \\n')\n",
    "    print(f'Total Time  : {elapsed_time:.4f} \\n')\n",
    "    \n",
    "    return train_history, valid_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "train_history, valid_history = main(\"\"\"채워주세요\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(1,epochs+1),y=train_history['loss'], label='Train')\n",
    "sns.lineplot(x=range(1,epochs+1),y=valid_history['loss'], label='Test')\n",
    "plt.title('Train vs Test Loss Graph')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(1,epochs+1),y=train_history['acc'], label='Train')\n",
    "sns.lineplot(x=range(1,epochs+1),y=valid_history['acc'], label='Test')\n",
    "plt.title('Train vs Test Accuracy Graph')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAM을 통한 해석\n",
    "\n",
    "resnet은 마지막에 GAP를 사용하기 때문에 따로 classifier를 수정하지 않아도 됨\n",
    "\n",
    "하지만 feature를 뽑아야 계산이 가능하기 때문에 get_activation 함수를 만들어야 함\n",
    "\n",
    "resnet forward 구조 : https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam을 위한 resnet 모델\n",
    "class resnet18_cam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(resnet18_cam, self).__init__()\n",
    "        \n",
    "        # Resnet 모델을 정의하고 catdog으로 학습시킨 파라미터 불러오기\n",
    "        base = resnet18(weights=None)\n",
    "\n",
    "        base.fc = \"\"\"채워주세요\"\"\"\n",
    "        parameters = torch.load(\"\"\"채워주세요\"\"\")['model']\n",
    "        base.load_state_dict(parameters)\n",
    "        \n",
    "        # feature extractor / resnet forward 구조 확인\n",
    "        self.feature_extractor = nn.Sequential(base.conv1,\n",
    "                                               base.bn1,\n",
    "                                               base.relu,\n",
    "                                               base.maxpool,\n",
    "                                               base.layer1,\n",
    "                                               base.layer2,\n",
    "                                               base.layer3,\n",
    "                                               base.layer4)\n",
    "        \n",
    "        # classifier / resnet forward 구조 확인\n",
    "        self.fc = nn.Sequential(base.avgpool, nn.Flatten(), base.fc)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # B, 3, 128, 128\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    # feature_extractor에서 나온 features를 반환\n",
    "    def get_activations(self, x):\n",
    "        return \"\"\"채워주세요\"\"\"\n",
    "    \n",
    "resnet_cam = resnet18_cam()\n",
    "resnet_cam.eval()\n",
    "\n",
    "summary(resnet_cam, input_size=(3,128,128), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_CAM(feature_conv, weight, class_idx):\n",
    "    # feats : N, 512, 8, 8\n",
    "    # weight : C, 512\n",
    "    # generate the class -activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        beforeDot =  feature_conv.reshape((nc, h*w))\n",
    "        cam = np.matmul(weight[idx], beforeDot) # 해당 class에 대한 weight에 featuremap 곱하기\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam) # minmax-saleing\n",
    "        cam_img = cam / np.max(cam) # minmax-saleing\n",
    "        cam_img = np.uint8(255 * cam_img)  # 0~255로 scale 변환\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "        \n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image\n",
    "import torchvision.transforms as tf\n",
    "img_path = './data/heros/test/Dr Strange/5.jpg'\n",
    "test_img = Image.open(img_path)\n",
    "plt.imshow(test_img)\n",
    "\n",
    "preprocess = tf.Compose([\n",
    "   tf.Resize((128,128)),\n",
    "   tf.ToTensor()\n",
    "])\n",
    "\n",
    "test_img = preprocess(test_img)\n",
    "test_img = test_img.unsqueeze(0) # 1, 3, 128, 128\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"\"\"채워주세요\"\"\" # resnet_cam에 test img를 넣어 class probability 얻기\n",
    "feat = \"\"\"채워주세요\"\"\" # resnet_cam에 test img를 넣어 feature 얻기 / get_activations 활용\n",
    "print(out.shape, feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax 함수를 적용하여 확률값 구하기\n",
    "h_x = F.softmax(out, dim=1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.detach().numpy()\n",
    "idx = idx.numpy()\n",
    "\n",
    "# las conv layer feature\n",
    "feat_numpy = feat.cpu().detach().numpy()\n",
    "\n",
    "params = list(resnet_cam.fc.parameters()) # params[0] : weight, params[1] : bias\n",
    "weight = np.squeeze(params[0].data.numpy())\n",
    "\n",
    "# Class Activation Map\n",
    "CAMs = return_CAM(feat_numpy, weight, [idx[0]])\n",
    "\n",
    "# CAM 결과 히트맵 시각화 & 저장\n",
    "img = cv2.imread(img_path) # numpy로 load : H,W,3\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.5 + img * 0.5\n",
    "\n",
    "cv2.imwrite('./results/CAM_result_Dr strange.png', result)\n",
    "plt.imshow(result/255.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
