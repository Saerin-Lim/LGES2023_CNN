{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korea\\anaconda3\\envs\\py39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch 기본 연산 단위 : Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch tensor : torch.int64\n",
      "pytorch tensor : torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f'pytorch tensor : {torch.tensor([1,2,3,4,5]).dtype}')\n",
    "print(f'pytorch tensor : {torch.tensor([1.0,2.0,3.0,4.0,5.0]).dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch 기본 정수 데이터 타입 torch.int64 | 텐서 타입 torch.LongTensor\n",
      "pytorch 기본 실수 데이터 타입 torch.float32 | 텐서 타입 torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "\n",
    "a_long = torch.LongTensor(a)\n",
    "a_float = torch.FloatTensor(a)\n",
    "\n",
    "print(f'pytorch 기본 정수 데이터 타입 {a_long.dtype} | 텐서 타입 {a_long.type()}')\n",
    "print(f'pytorch 기본 실수 데이터 타입 {a_float.dtype} | 텐서 타입 {a_float.type()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type 변경방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경 전 data type : torch.int64\n",
      "변경 후 data type : torch.float32\n",
      "변경 후 data type : torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.LongTensor([1,2,3,4,5])\n",
    "print(f'변경 전 data type : {a.dtype}')\n",
    "print(f'변경 후 data type : {a.type(torch.FloatTensor).dtype}')\n",
    "print(f'변경 후 data type : {a.float().dtype}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy to tensor / tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.IntTensor\n",
      "torch.IntTensor\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "a = np.array([1,2,3,4,5])\n",
    "print(torch.from_numpy(a).type())\n",
    "print(torch.tensor(a).type())\n",
    "print(torch.LongTensor(a).type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "a = torch.LongTensor([1,2,3,4,5])\n",
    "print(type(a.numpy()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU & GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU를 사용할 수 있는지 없는지 확인\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor의 위치 확인\n",
    "a = torch.FloatTensor([1,2,3,4,5])\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CPU to GPU\n",
    "print(a.cuda().device)\n",
    "print(a.to('cuda:0').device)\n",
    "print(a.to(0).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 to cpu\n",
      "cuda:0 to cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU to CPU\n",
    "a = torch.FloatTensor([1,2,3,4,5]).to(0)\n",
    "print(f'{a.device} to {a.cpu().device}')\n",
    "print(f'{a.device} to {a.to(\"cpu\").device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 텐서의 위치가 다르면 에러 발생\u001b[39;00m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# 텐서의 위치가 다르면 에러 발생\n",
    "a = torch.FloatTensor([1,2,3,4,5]).to(0)\n",
    "a + a.cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 조작하기\n",
    "##### 1. index를 활용한 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 8., 9.])\n",
      "tensor([7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i번째 row 선택\n",
    "i=2\n",
    "print(a[i])\n",
    "print(a[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5., 8.])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 j번째 column 선택\n",
    "j=1\n",
    "print(a[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i번째 row,j번째 column element 선택\n",
    "i,j = 2,1\n",
    "print(a[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i~j-1까지 row or column 선택\n",
    "i,j = 1,3\n",
    "print(a[i:j,:])\n",
    "print(a[:,i:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 6.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(a[1:3,1:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 특정 조건을 만족하는 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 3, 4, 3, 4, 5, 1, 4, 4, 3, 3, 3, 1, 1, 0, 1, 3, 1, 1, 2, 1, 2, 2, 1,\n",
      "        4, 2, 4, 4, 0, 0, 1, 2])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# 특정 조건을 만족하는 element 선택 -> 특정 조건을 만족하는지 만족하지 않는지 True False mask를 만들어야 함\n",
    "# ex1) 클래스가 5인 x만을 선택\n",
    "x = torch.randn(size=(32,5)) # 특징(X)이 5개 있는 입력 변수 32개 생성\n",
    "labels = torch.randint(0,6,size=(32,)) # 0~5의 class를 가지는 출력 변수 32개 생성\n",
    "print(labels)\n",
    "print((labels==5).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False])\n",
      "tensor([[ 0.7928,  2.0665,  0.7490,  0.2729, -0.0196],\n",
      "        [-0.1831, -0.9246, -0.8593, -0.5203,  0.5959]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "mask = labels == 5\n",
    "print(mask)\n",
    "\n",
    "print(x[mask])\n",
    "print(x[mask].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False])\n",
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False])\n",
      "tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# mask를 만드는 방법\n",
    "print(labels==5)\n",
    "print(torch.where(labels==5,True,False))\n",
    "print(labels.eq(5))\n",
    "\n",
    "# 참고 : element-wise compairsion function / 두 텐서간 비교도 가능\n",
    "\n",
    "# torch.ne = not_equal\n",
    "# torch.eq = equal\n",
    "# torch.ge = greater_equal\n",
    "# torch.le = less_equal\n",
    "# torch.greater\n",
    "# torch.less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False,  True,  True, False, False,\n",
      "        False, False])\n",
      "tensor([ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False,  True,  True, False, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# 다중조건 mask를 만드는 방법\n",
    "print((labels>=3) & (labels<=5))\n",
    "print(torch.mul(labels>=3,labels<=5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.특정 조건을 만족하는 데이터의 인덱스 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 4, 0, 5, 1, 1, 1, 2, 1, 0, 1, 3, 3, 5, 3, 0, 1, 5, 2, 1, 1, 5, 2, 1,\n",
      "        2, 3, 4, 5, 0, 2, 4, 1])\n",
      "tensor(6)\n",
      "tensor([ True, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False,  True, False, False,\n",
      "        False,  True, False, False, False, False, False,  True, False, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(32,5))\n",
    "labels = torch.randint(0,6,size=(32,))\n",
    "print(labels)\n",
    "print((labels==5).sum())\n",
    "\n",
    "mask = labels==5\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0],\n",
      "        [ 3],\n",
      "        [13],\n",
      "        [17],\n",
      "        [21],\n",
      "        [27]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(mask))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 연산"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 통계량 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(5.)\n",
      "tensor(2.7386)\n",
      "tensor(9.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# sum, mean, max, min, std\n",
    "print(torch.sum(a)) # a.sum()\n",
    "print(torch.mean(a)) # a.mean()\n",
    "print(torch.std(a)) # a.std()\n",
    "print(torch.max(a)) # a.max()\n",
    "print(torch.min(a)) # a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12., 15., 18.])\n",
      "tensor([4., 5., 6.])\n",
      "tensor([3., 3., 3.])\n",
      "torch.return_types.max(\n",
      "values=tensor([7., 8., 9.]),\n",
      "indices=tensor([2, 2, 2]))\n",
      "torch.return_types.min(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension을 기준으로 계산\n",
    "print(torch.sum(a, dim=0))\n",
    "print(torch.mean(a, dim=0))\n",
    "print(torch.std(a, dim=0))\n",
    "print(torch.max(a, dim=0)) # 최대값과 최대값 인덱스를 같이 반환\n",
    "print(torch.min(a, dim=0)) # 최소값과 최소값 인덱스를 같이 반환"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. element-wise 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([1,2,3,4,5,6])\n",
    "b = torch.FloatTensor([4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상수항 더하기 : tensor([2., 3., 4., 5., 6., 7.])\n",
      "상수항 곱하기 : tensor([ 2.,  4.,  6.,  8., 10., 12.])\n"
     ]
    }
   ],
   "source": [
    "print(f'상수항 더하기 : {a + 1}')\n",
    "print(f'상수항 곱하기 : {a * 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 텐서 간 element-wise 더하기 : tensor([ 5.,  7.,  9., 11., 13., 15.])\n",
      "두 텐서 간 element-wise 곱하기 : tensor([ 4., 10., 18., 28., 40., 54.])\n"
     ]
    }
   ],
   "source": [
    "print(f'두 텐서 간 element-wise 더하기 : {a + b}')\n",
    "print(f'두 텐서 간 element-wise 곱하기 : {a * b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수를 활용한 element-wise 더하기 : tensor([2., 3., 4., 5., 6., 7.])\n",
      "함수를 활용한 element-wise 더하기 : tensor([ 5.,  7.,  9., 11., 13., 15.])\n",
      "함수를 활용한 element-wise 곱하기 : tensor([ 2.,  4.,  6.,  8., 10., 12.])\n",
      "함수를 활용한 element-wise 곱하기 : tensor([ 4., 10., 18., 28., 40., 54.])\n"
     ]
    }
   ],
   "source": [
    "print(f'함수를 활용한 element-wise 더하기 : {torch.add(a,1)}')\n",
    "print(f'함수를 활용한 element-wise 더하기 : {torch.add(a,b)}')\n",
    "print(f'함수를 활용한 element-wise 곱하기 : {torch.mul(a,2)}')\n",
    "print(f'함수를 활용한 element-wise 곱하기 : {torch.mul(a,b)}')\n",
    "# 나누기 = torch.div\n",
    "# 제곱 = torch.pow\n",
    "# 지수 = torch.exp\n",
    "# 로그 = torch.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.,  2.,  3.],\n",
      "        [18.,  5.,  6.],\n",
      "        [24.,  8.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension만 더하고 싶으면 해당 dimension의 data를 선택한 후 변경\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "\n",
    "b = torch.FloatTensor([[11,12,13],\n",
    "                       [14,15,16],\n",
    "                       [17,18,19]])\n",
    "\n",
    "a[:,0] = a[:,0] + b[:,0]\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 벡터/행렬 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40)\n",
      "tensor([[ 2,  3,  4,  5],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 6,  9, 12, 15],\n",
      "        [ 8, 12, 16, 20]])\n"
     ]
    }
   ],
   "source": [
    "# 두 벡터 간 내적 외적\n",
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([2,3,4,5])\n",
    "c = torch.dot(a,b)\n",
    "print(c) # tensor(40)\n",
    "\n",
    "d = torch.outer(a,b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# 벡터, 행렬 전치\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "print(a.t()) # a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 8, 4],\n",
      "        [9, 9, 8, 9],\n",
      "        [9, 7, 8, 4],\n",
      "        [5, 3, 2, 9],\n",
      "        [1, 3, 8, 1]])\n",
      "tensor([[6, 6, 1, 3],\n",
      "        [2, 9, 7, 5],\n",
      "        [3, 6, 9, 9],\n",
      "        [5, 6, 4, 1],\n",
      "        [5, 5, 3, 6],\n",
      "        [7, 1, 4, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱\n",
    "a = torch.randint(1,10, size=(5,4))\n",
    "b = torch.randint(1,10, size=(6,4))\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 92, 149, 165, 103, 108,  98],\n",
      "        [143, 200, 234, 140, 168, 158],\n",
      "        [116, 157, 177, 123, 128, 126],\n",
      "        [ 77,  96, 132,  60, 100, 100],\n",
      "        [ 35,  90, 102,  56,  50,  48]])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "#matmul은 행렬-벡터 간 연산 가능, mm은 행렬-행렬만 지원\n",
    "c = torch.matmul(a,b.t()) # torch.mm(a,b.T)\n",
    "\n",
    "print(c)\n",
    "print(c.shape) # c.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 텐서 결합/분해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [11., 12., 13.],\n",
      "        [14., 15., 16.],\n",
      "        [17., 18., 19.]]) torch.Size([6, 3])\n",
      "tensor([[ 1.,  2.,  3., 11., 12., 13.],\n",
      "        [ 4.,  5.,  6., 14., 15., 16.],\n",
      "        [ 7.,  8.,  9., 17., 18., 19.]]) torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "\n",
    "b = torch.FloatTensor([[11,12,13],\n",
    "                       [14,15,16],\n",
    "                       [17,18,19]])\n",
    "\n",
    "row_cat = torch.cat((a,b),dim=0)\n",
    "col_cat = torch.cat((a,b),dim=1)\n",
    "\n",
    "print(row_cat, row_cat.shape)\n",
    "print(col_cat, col_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[11., 12., 13.],\n",
      "         [14., 15., 16.],\n",
      "         [17., 18., 19.]]]) torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "stack_dim0 = torch.stack((a,b),dim=0)\n",
    "print(stack_dim0, stack_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [11., 12., 13.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.],\n",
      "         [14., 15., 16.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.],\n",
      "         [17., 18., 19.]]]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "stack_dim1 = torch.stack((a,b),dim=1)\n",
    "print(stack_dim1, stack_dim1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]), tensor([[-1., -2., -3.]]), tensor([[-4., -5., -6.]]))\n"
     ]
    }
   ],
   "source": [
    "# 하나의 텐서를 n개의 텐서로 분해하기\n",
    "a = torch.FloatTensor([\n",
    "    [ 1.,  2.,  3.],\n",
    "    [ 4.,  5.,  6.],\n",
    "    [-1., -2., -3.],\n",
    "    [-4., -5., -6.]\n",
    "])\n",
    "print(torch.chunk(a,chunks=4,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]), tensor([[-1., -2., -3.]]), tensor([[-4., -5., -6.]]))\n"
     ]
    }
   ],
   "source": [
    "# 하나의 텐서를 n개의 row를 가지는 텐서로 분리하기\n",
    "print(torch.split(a,split_size_or_sections=1,dim=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 차원 늘리기/줄이기/바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 차원 늘리기\n",
    "a = torch.randn(size=(10,3))\n",
    "b = torch.randn(size=(3,))\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 차원의 개수가 다르면 에러 발생\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "# 차원의 개수가 다르면 에러 발생\n",
    "print(torch.cat((a,b),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((a,b.unsqueeze(dim=0)),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3])\n"
     ]
    }
   ],
   "source": [
    "# 차원 줄이기\n",
    "a = torch.randn(size=(1,10,3))\n",
    "b = torch.randn(size=(5,3))\n",
    "\n",
    "print(torch.cat((a.squeeze(dim=0),b),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3]) -> torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 차원 변경\n",
    "image = torch.randn(size=(32,32,3))\n",
    "print(f'{image.shape} -> {image.transpose(0,2).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3, 128]) -> torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 차원을 여러 개로 변경\n",
    "images = torch.randn(size=(32,32,3,128))\n",
    "print(f'{images.shape} -> {images.permute(3,2,0,1).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n",
      "torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 차원 재배열\n",
    "image = torch.randn(size=(3,32,32))\n",
    "\n",
    "print(image.reshape(3,32*32).shape)\n",
    "print(image.view(3,32*32).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch 자동미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = x**3 + 2*x**2+7\n",
    "    return y\n",
    "\n",
    "def g(x):\n",
    "    y = x**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_x를 x로 미분한 값 : 39.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "f_x = f(x)\n",
    "f_x.backward()\n",
    "print(f'f_x를 x로 미분한 값 : {x.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_x를 x로 미분한 값 : 6.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "g_x = g(x)\n",
    "g_x.backward()\n",
    "print(f'g_x를 x로 미분한 값 : {x.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g(f(x))를 x로 미분한 값 = f'(3)*g'(f(3)) = 39*2*52 = 4056.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "g_f_x = g(f(x))\n",
    "g_f_x.backward()\n",
    "print(f\"g(f(x))를 x로 미분한 값 = f'(3)*g'(f(3)) = 39*2*52 = {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size=(10,)) # 입력 변수가 10개인 관측치 한 개\n",
    "y = torch.tensor(1.0) # x에 해당하는 출력 변수\n",
    "\n",
    "w1 = torch.randn(size=(10,5),requires_grad=True) # linear layer1\n",
    "w2 = torch.randn(size=(5,1),requires_grad=True) # linear layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([168.9308], grad_fn=<PowBackward0>)\n",
      "tensor([[  1.5966,  -2.5086,   1.7700,   9.1995,   3.1415],\n",
      "        [ -1.4277,   2.2432,  -1.5828,  -8.2264,  -2.8092],\n",
      "        [-11.9845,  18.8300, -13.2859, -69.0532, -23.5808],\n",
      "        [ 17.3093, -27.1964,  19.1890,  99.7346,  34.0580],\n",
      "        [-16.8010,  26.3977, -18.6255, -96.8055, -33.0578],\n",
      "        [  4.6662,  -7.3314,   5.1729,  26.8859,   9.1812],\n",
      "        [ 11.9748, -18.8147,  13.2752,  68.9973,  23.5617],\n",
      "        [ -6.7186,  10.5562,  -7.4482, -38.7116, -13.2195],\n",
      "        [ 13.9038, -21.8456,  15.4137,  80.1123,  27.3573],\n",
      "        [  3.8971,  -6.1231,   4.3203,  22.4544,   7.6679]])\n",
      "tensor([[ 17.8550],\n",
      "        [ -8.5876],\n",
      "        [163.5132],\n",
      "        [117.5072],\n",
      "        [ 51.7092]])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.matmul((torch.matmul(x,w1)),w2) # forward\n",
    "\n",
    "loss = (y-y_pred)**2 # MSE Loss 계산\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward() #backward\n",
    "\n",
    "print(w1.grad)\n",
    "print(w2.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zero_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True) \n",
      "\n",
      "First call\n",
      "tensor([4., 6., 8.])\n",
      "\n",
      "Second call\n",
      "tensor([ 8., 12., 16.])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([4., 6., 8.])\n"
     ]
    }
   ],
   "source": [
    "# backward를 통해 계산된 gradient는 backward를 할 때마다 누적\n",
    "# 따라서 backward를 한 번 한 뒤, 초기화가 필요\n",
    "\n",
    "x = torch.FloatTensor([1,2,3])\n",
    "x.requires_grad = True\n",
    "print(x, '\\n')\n",
    "out = (x+1).pow(2).t() # 미분함수 f'(x) = 2(x+1)\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "\n",
    "print(f\"First call\\n{x.grad}\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "\n",
    "print(f\"\\nSecond call\\n{x.grad}\")\n",
    "x.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{x.grad}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward 단계에서 detach 이전 layer에는 gradient 계산을 멈춤\n",
    "\n",
    "x = torch.randn(size=(10,)) # 입력변수가 10개인 관측치\n",
    "y = torch.tensor(1.0)\n",
    "\n",
    "w1 = torch.randn(size=(10,5),requires_grad=True)\n",
    "w2 = torch.randn(size=(5,1),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([52.5626], grad_fn=<PowBackward0>)\n",
      "None\n",
      "tensor([[ 32.0475],\n",
      "        [-88.1717],\n",
      "        [ 28.8982],\n",
      "        [-43.5469],\n",
      "        [  0.5812]])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.matmul((torch.matmul(x,w1)).detach(),w2)\n",
    "\n",
    "loss = (y-y_pred)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(w1.grad)\n",
    "print(w2.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward를 위한 computation graph를 만드는 것은 연산 시간을 늘림\n",
    "# backward가 필요없는 구간에서는 자동 미분을 끄는 용도 (모델 테스트 단계)\n",
    "\n",
    "x = torch.randn(size=(10,)) # 입력변수가 10개인 관측치\n",
    "y = torch.tensor(1.0)\n",
    "\n",
    "w1 = torch.randn(size=(10,5),requires_grad=True)\n",
    "w2 = torch.randn(size=(5,1),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1091])\n",
      "tensor([9.6664])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch.matmul((torch.matmul(x,w1)).detach(),w2)\n",
    "\n",
    "    loss = (y-y_pred)**2\n",
    "\n",
    "print(y_pred)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
