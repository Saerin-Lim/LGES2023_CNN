{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch 기본 연산 단위 : Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch tensor : torch.int64\n",
      "pytorch tensor : torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f'pytorch tensor : {torch.tensor([1,2,3,4,5]).dtype}')\n",
    "print(f'pytorch tensor : {torch.tensor([1.0,2.0,3.0,4.0,5.0]).dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch 기본 정수 데이터 타입 torch.int64 | 텐서 타입 torch.LongTensor\n",
      "pytorch 기본 실수 데이터 타입 torch.float32 | 텐서 타입 torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "\n",
    "a_long = torch.LongTensor(a)  \n",
    "\n",
    "a_float = torch.FloatTensor(a)\n",
    "\n",
    "print(f'pytorch 기본 정수 데이터 타입 {a_long.dtype} | 텐서 타입 {a_long.type()}')\n",
    "print(f'pytorch 기본 실수 데이터 타입 {a_float.dtype} | 텐서 타입 {a_float.type()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type 변경방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경 전 data type : torch.int64\n",
      "변경 후 data type : torch.float32\n",
      "변경 후 data type : torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.LongTensor([1,2,3,4,5])\n",
    "print(f'변경 전 data type : {a.dtype}')\n",
    "print(f'변경 후 data type : {a.type(torch.FloatTensor).dtype}')\n",
    "print(f'변경 후 data type : {a.float().dtype}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy to tensor / tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.IntTensor\n",
      "torch.IntTensor\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "a = np.array([1,2,3,4,5])\n",
    "print(torch.from_numpy(a).type())\n",
    "print(torch.tensor(a).type())\n",
    "print(torch.LongTensor(a).type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "a = torch.LongTensor([1,2,3,4,5])\n",
    "print(type(a.numpy()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU & GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU를 사용할 수 있는지 없는지 확인\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor의 위치 확인\n",
    "a = torch.FloatTensor([1,2,3,4,5])\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CPU to GPU\n",
    "print(a.cuda().device)\n",
    "print(a.to('cuda:0').device)\n",
    "print(a.to(0).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 to cpu\n",
      "cuda:0 to cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU to CPU\n",
    "a = torch.FloatTensor([1,2,3,4,5]).to(0)\n",
    "print(f'{a.device} to {a.cpu().device}')\n",
    "print(f'{a.device} to {a.to(\"cpu\").device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\korea\\OneDrive - 고려대학교\\프로젝트\\[2023]LG엔솔-기업교육\\실습 자료\\0616_CNN1\\pytorch_tutorial1_기초.ipynb 셀 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/korea/OneDrive%20-%20%EA%B3%A0%EB%A0%A4%EB%8C%80%ED%95%99%EA%B5%90/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%5B2023%5DLG%EC%97%94%EC%86%94-%EA%B8%B0%EC%97%85%EA%B5%90%EC%9C%A1/%EC%8B%A4%EC%8A%B5%20%EC%9E%90%EB%A3%8C/0616_CNN1/pytorch_tutorial1_%EA%B8%B0%EC%B4%88.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 텐서의 위치가 다르면 에러 발생\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/korea/OneDrive%20-%20%EA%B3%A0%EB%A0%A4%EB%8C%80%ED%95%99%EA%B5%90/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%5B2023%5DLG%EC%97%94%EC%86%94-%EA%B8%B0%EC%97%85%EA%B5%90%EC%9C%A1/%EC%8B%A4%EC%8A%B5%20%EC%9E%90%EB%A3%8C/0616_CNN1/pytorch_tutorial1_%EA%B8%B0%EC%B4%88.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m])\u001b[39m.\u001b[39mto(\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/korea/OneDrive%20-%20%EA%B3%A0%EB%A0%A4%EB%8C%80%ED%95%99%EA%B5%90/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%5B2023%5DLG%EC%97%94%EC%86%94-%EA%B8%B0%EC%97%85%EA%B5%90%EC%9C%A1/%EC%8B%A4%EC%8A%B5%20%EC%9E%90%EB%A3%8C/0616_CNN1/pytorch_tutorial1_%EA%B8%B0%EC%B4%88.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a \u001b[39m+\u001b[39;49m a\u001b[39m.\u001b[39;49mcpu()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# 텐서의 위치가 다르면 에러 발생\n",
    "a = torch.FloatTensor([1,2,3,4,5]).to(0)\n",
    "a + a.cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 조작하기\n",
    "##### 1. index를 활용한 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 8., 9.])\n",
      "tensor([7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i번째 row 선택\n",
    "i=2\n",
    "print(a[i])\n",
    "print(a[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5., 8.])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 j번째 column 선택\n",
    "j=1\n",
    "print(a[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i번째 row,j번째 column element 선택\n",
    "i,j = 2,1\n",
    "print(a[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# index를 활용한 i~j-1까지 row or column 선택\n",
    "i,j = 1,3\n",
    "print(a[i:j,:])\n",
    "print(a[:,i:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 6.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(a[1:3,1:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 특정 조건을 만족하는 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 3, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 5, 0, 3, 2, 0, 4, 1, 4, 5, 2,\n",
      "        4, 1, 5, 5, 2, 4, 2, 2])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# 특정 조건을 만족하는 element 선택 -> 특정 조건을 만족하는지 만족하지 않는지 True False mask를 만들어야 함\n",
    "# ex1) 클래스가 5인 x만을 선택\n",
    "x = torch.randn(size=(32,5)) # 특징(X)이 5개 있는 입력 변수 32개 생성\n",
    "labels = torch.randint(0,6,size=(32,)) # 0~5의 class를 가지는 출력 변수 32개 생성\n",
    "print(labels)\n",
    "print((labels==5).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True,  True, False, False,\n",
      "        False, False])\n",
      "tensor([[-0.1193,  0.8909, -0.2050,  2.7981, -0.3882],\n",
      "        [ 0.4152, -0.0591, -1.1600,  0.7490, -0.0057],\n",
      "        [ 0.4175,  1.1197,  1.1258, -0.2742,  0.2716],\n",
      "        [-0.5360,  1.5532, -0.3428,  2.0004, -0.1741]])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "mask = labels == 5\n",
    "print(mask)\n",
    "\n",
    "print(x[mask])\n",
    "print(x[mask].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True,  True, False, False,\n",
      "        False, False])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True,  True, False, False,\n",
      "        False, False])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True,  True, False, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# mask를 만드는 방법\n",
    "print(labels==5)\n",
    "print(torch.where(labels==5,True,False))\n",
    "print(labels.eq(5))\n",
    "\n",
    "# 참고 : element-wise compairsion function / 두 텐서간 비교도 가능\n",
    "\n",
    "# torch.ne = not_equal\n",
    "# torch.eq = equal\n",
    "# torch.ge = greater_equal\n",
    "# torch.le = less_equal\n",
    "# torch.greater\n",
    "# torch.less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False,  True, False, False,  True,\n",
      "        False,  True,  True, False,  True, False,  True,  True, False,  True,\n",
      "        False, False])\n",
      "tensor([False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False,  True, False, False,  True,\n",
      "        False,  True,  True, False,  True, False,  True,  True, False,  True,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "# 다중조건 mask를 만드는 방법\n",
    "print((labels>=3) & (labels<=5))\n",
    "print(torch.mul(labels>=3,labels<=5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.특정 조건을 만족하는 데이터의 인덱스 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 4, 1, 4, 4, 2, 5, 2, 1, 1, 4, 1, 3, 1, 5, 4, 1, 5, 4, 3, 0, 3, 3,\n",
      "        1, 2, 1, 5, 3, 3, 2, 3])\n",
      "tensor(4)\n",
      "tensor([False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(32,5))\n",
    "labels = torch.randint(0,6,size=(32,))\n",
    "print(labels)\n",
    "print((labels==5).sum())\n",
    "\n",
    "mask = labels==5\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7],\n",
      "        [15],\n",
      "        [18],\n",
      "        [27]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(mask))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 연산"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 통계량 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(5.)\n",
      "tensor(2.7386)\n",
      "tensor(9.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# sum, mean, max, min, std\n",
    "print(torch.sum(a)) # a.sum()\n",
    "print(torch.mean(a)) # a.mean()\n",
    "print(torch.std(a)) # a.std()\n",
    "print(torch.max(a)) # a.max()\n",
    "print(torch.min(a)) # a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12., 15., 18.])\n",
      "tensor([4., 5., 6.])\n",
      "tensor([3., 3., 3.])\n",
      "torch.return_types.max(\n",
      "values=tensor([7., 8., 9.]),\n",
      "indices=tensor([2, 2, 2]))\n",
      "torch.return_types.min(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension을 기준으로 계산\n",
    "print(torch.sum(a, dim=0))\n",
    "print(torch.mean(a, dim=0))\n",
    "print(torch.std(a, dim=0))\n",
    "print(torch.max(a, dim=0)) # 최대값과 최대값 인덱스를 같이 반환\n",
    "print(torch.min(a, dim=0)) # 최소값과 최소값 인덱스를 같이 반환"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. element-wise 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([1,2,3,4,5,6])\n",
    "b = torch.FloatTensor([4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상수항 더하기 : tensor([2., 3., 4., 5., 6., 7.])\n",
      "상수항 곱하기 : tensor([ 2.,  4.,  6.,  8., 10., 12.])\n"
     ]
    }
   ],
   "source": [
    "print(f'상수항 더하기 : {a + 1}')\n",
    "print(f'상수항 곱하기 : {a * 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 텐서 간 element-wise 더하기 : tensor([ 5.,  7.,  9., 11., 13., 15.])\n",
      "두 텐서 간 element-wise 곱하기 : tensor([ 4., 10., 18., 28., 40., 54.])\n"
     ]
    }
   ],
   "source": [
    "print(f'두 텐서 간 element-wise 더하기 : {a + b}')\n",
    "print(f'두 텐서 간 element-wise 곱하기 : {a * b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수를 활용한 element-wise 더하기 : tensor([2., 3., 4., 5., 6., 7.])\n",
      "함수를 활용한 element-wise 더하기 : tensor([ 5.,  7.,  9., 11., 13., 15.])\n",
      "함수를 활용한 element-wise 곱하기 : tensor([ 2.,  4.,  6.,  8., 10., 12.])\n",
      "함수를 활용한 element-wise 곱하기 : tensor([ 4., 10., 18., 28., 40., 54.])\n"
     ]
    }
   ],
   "source": [
    "print(f'함수를 활용한 element-wise 더하기 : {torch.add(a,1)}')\n",
    "print(f'함수를 활용한 element-wise 더하기 : {torch.add(a,b)}')\n",
    "print(f'함수를 활용한 element-wise 곱하기 : {torch.mul(a,2)}')\n",
    "print(f'함수를 활용한 element-wise 곱하기 : {torch.mul(a,b)}')\n",
    "# 나누기 = torch.div\n",
    "# 제곱 = torch.pow\n",
    "# 지수 = torch.exp\n",
    "# 로그 = torch.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.,  2.,  3.],\n",
      "        [18.,  5.,  6.],\n",
      "        [24.,  8.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "# 특정 dimension만 더하고 싶으면 해당 dimension의 data를 선택한 후 변경\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "\n",
    "b = torch.FloatTensor([[11,12,13],\n",
    "                       [14,15,16],\n",
    "                       [17,18,19]])\n",
    "\n",
    "a[:,0] = a[:,0] + b[:,0]\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 벡터/행렬 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40)\n",
      "tensor([[ 2,  3,  4,  5],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 6,  9, 12, 15],\n",
      "        [ 8, 12, 16, 20]])\n"
     ]
    }
   ],
   "source": [
    "# 두 벡터 간 내적 외적\n",
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([2,3,4,5])\n",
    "c = torch.dot(a,b)\n",
    "print(c) # tensor(40)\n",
    "\n",
    "d = torch.outer(a,b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# 벡터, 행렬 전치\n",
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "print(a.t()) # a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 7, 8],\n",
      "        [5, 4, 4, 8],\n",
      "        [1, 6, 8, 9],\n",
      "        [2, 8, 2, 8],\n",
      "        [3, 1, 6, 6]])\n",
      "tensor([[1, 9, 2, 3],\n",
      "        [5, 9, 3, 8],\n",
      "        [9, 5, 2, 1],\n",
      "        [1, 5, 3, 8],\n",
      "        [1, 8, 8, 6],\n",
      "        [4, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱\n",
    "a = torch.randint(1,10, size=(5,4))\n",
    "b = torch.randint(1,10, size=(6,4))\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 49, 104,  45,  92, 114,  79],\n",
      "        [ 73, 137,  81, 101, 117,  88],\n",
      "        [ 98, 155,  64, 127, 167,  99],\n",
      "        [102, 152,  70, 112, 130,  80],\n",
      "        [ 42,  90,  50,  74,  95,  69]])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "#matmul은 행렬-벡터 간 연산 가능, mm은 행렬-행렬만 지원\n",
    "c = torch.matmul(a,b.t()) # torch.mm(a,b.T)\n",
    "\n",
    "print(c)\n",
    "print(c.shape) # c.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 텐서 결합/분해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [11., 12., 13.],\n",
      "        [14., 15., 16.],\n",
      "        [17., 18., 19.]]) torch.Size([6, 3])\n",
      "tensor([[ 1.,  2.,  3., 11., 12., 13.],\n",
      "        [ 4.,  5.,  6., 14., 15., 16.],\n",
      "        [ 7.,  8.,  9., 17., 18., 19.]]) torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "\n",
    "b = torch.FloatTensor([[11,12,13],\n",
    "                       [14,15,16],\n",
    "                       [17,18,19]])\n",
    "\n",
    "row_cat = torch.cat((a,b),dim=0)\n",
    "col_cat = torch.cat((a,b),dim=1)\n",
    "\n",
    "print(row_cat, row_cat.shape)\n",
    "print(col_cat, col_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[11., 12., 13.],\n",
      "         [14., 15., 16.],\n",
      "         [17., 18., 19.]]]) torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "stack_dim0 = torch.stack((a,b),dim=0)\n",
    "print(stack_dim0, stack_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [11., 12., 13.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.],\n",
      "         [14., 15., 16.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.],\n",
      "         [17., 18., 19.]]]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "stack_dim1 = torch.stack((a,b),dim=1)\n",
    "print(stack_dim1, stack_dim1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]), tensor([[-1., -2., -3.]]), tensor([[-4., -5., -6.]]))\n"
     ]
    }
   ],
   "source": [
    "# 하나의 텐서를 n개의 텐서로 분해하기\n",
    "a = torch.FloatTensor([\n",
    "    [ 1.,  2.,  3.],\n",
    "    [ 4.,  5.,  6.],\n",
    "    [-1., -2., -3.],\n",
    "    [-4., -5., -6.]\n",
    "])\n",
    "print(torch.chunk(a,chunks=4,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]), tensor([[-1., -2., -3.]]), tensor([[-4., -5., -6.]]))\n"
     ]
    }
   ],
   "source": [
    "# 하나의 텐서를 n개의 row를 가지는 텐서로 분리하기\n",
    "print(torch.split(a,split_size_or_sections=1,dim=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 차원 늘리기/줄이기/바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 차원 늘리기\n",
    "a = torch.randn(size=(10,3))\n",
    "b = torch.randn(size=(3,))\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\korea\\OneDrive - 고려대학교\\프로젝트\\[2023]LG엔솔-기업교육\\실습 자료\\0616_CNN1\\pytorch_tutorial1_기초.ipynb 셀 55\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/korea/OneDrive%20-%20%EA%B3%A0%EB%A0%A4%EB%8C%80%ED%95%99%EA%B5%90/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%5B2023%5DLG%EC%97%94%EC%86%94-%EA%B8%B0%EC%97%85%EA%B5%90%EC%9C%A1/%EC%8B%A4%EC%8A%B5%20%EC%9E%90%EB%A3%8C/0616_CNN1/pytorch_tutorial1_%EA%B8%B0%EC%B4%88.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 차원의 개수가 다르면 에러 발생\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/korea/OneDrive%20-%20%EA%B3%A0%EB%A0%A4%EB%8C%80%ED%95%99%EA%B5%90/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%5B2023%5DLG%EC%97%94%EC%86%94-%EA%B8%B0%EC%97%85%EA%B5%90%EC%9C%A1/%EC%8B%A4%EC%8A%B5%20%EC%9E%90%EB%A3%8C/0616_CNN1/pytorch_tutorial1_%EA%B8%B0%EC%B4%88.ipynb#Y105sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mcat((a,b),dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "# 차원의 개수가 다르면 에러 발생\n",
    "print(torch.cat((a,b),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((a,b.unsqueeze(dim=0)),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3])\n"
     ]
    }
   ],
   "source": [
    "# 차원 줄이기\n",
    "a = torch.randn(size=(1,10,3))\n",
    "b = torch.randn(size=(5,3))\n",
    "\n",
    "print(torch.cat((a.squeeze(dim=0),b),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3]) -> torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 차원 변경\n",
    "image = torch.randn(size=(32,32,3))\n",
    "print(f'{image.shape} -> {image.transpose(0,2).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3, 128]) -> torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 차원을 여러 개로 변경\n",
    "images = torch.randn(size=(32,32,3,128))\n",
    "print(f'{images.shape} -> {images.permute(3,2,0,1).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n",
      "torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 차원 재배열\n",
    "image = torch.randn(size=(3,32,32))\n",
    "\n",
    "print(image.reshape(3,32*32).shape)\n",
    "print(image.view(3,32*32).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch 자동미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = x**3 + 2*x**2+7\n",
    "    return y\n",
    "\n",
    "def g(x):\n",
    "    y = x**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_x를 x로 미분한 값 : 39.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "f_x = f(x)\n",
    "f_x.backward()\n",
    "print(f'f_x를 x로 미분한 값 : {x.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_x를 x로 미분한 값 : 6.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "g_x = g(x)\n",
    "g_x.backward()\n",
    "print(f'g_x를 x로 미분한 값 : {x.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g(f(x))를 x로 미분한 값 = f'(3)*g'(f(3)) = 39*2*52 = 4056.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "g_f_x = g(f(x))\n",
    "g_f_x.backward()\n",
    "print(f\"g(f(x))를 x로 미분한 값 = f'(3)*g'(f(3)) = 39*2*52 = {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size=(10,)) # 입력 변수가 10개인 관측치 한 개\n",
    "y = torch.tensor(1.0) # x에 해당하는 출력 변수\n",
    "\n",
    "w1 = torch.randn(size=(10,5),requires_grad=True) # linear layer1\n",
    "w2 = torch.randn(size=(5,1),requires_grad=True) # linear layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4032], grad_fn=<PowBackward0>)\n",
      "tensor([[ 1.5784,  0.5014,  1.8236, -0.1129, -0.1605],\n",
      "        [-0.6406, -0.2035, -0.7401,  0.0458,  0.0652],\n",
      "        [-1.6631, -0.5283, -1.9215,  0.1189,  0.1691],\n",
      "        [ 0.1731,  0.0550,  0.1999, -0.0124, -0.0176],\n",
      "        [ 1.8246,  0.5796,  2.1080, -0.1305, -0.1856],\n",
      "        [-0.0878, -0.0279, -0.1014,  0.0063,  0.0089],\n",
      "        [-0.9341, -0.2967, -1.0792,  0.0668,  0.0950],\n",
      "        [-1.0197, -0.3239, -1.1781,  0.0729,  0.1037],\n",
      "        [ 2.2308,  0.7086,  2.5774, -0.1595, -0.2269],\n",
      "        [-1.1647, -0.3700, -1.3456,  0.0833,  0.1185]])\n",
      "tensor([[-5.9493],\n",
      "        [ 4.4632],\n",
      "        [ 2.5358],\n",
      "        [ 4.3600],\n",
      "        [ 0.4682]])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.matmul((torch.matmul(x,w1)),w2) # forward\n",
    "\n",
    "loss = (y-y_pred)**2 # MSE Loss 계산\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward() #backward\n",
    "\n",
    "print(w1.grad)\n",
    "print(w2.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zero_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True) \n",
      "\n",
      "First call\n",
      "tensor([4., 6., 8.])\n",
      "\n",
      "Second call\n",
      "tensor([ 8., 12., 16.])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([4., 6., 8.])\n"
     ]
    }
   ],
   "source": [
    "# backward를 통해 계산된 gradient는 backward를 할 때마다 누적\n",
    "# 따라서 backward를 한 번 한 뒤, 초기화가 필요\n",
    "\n",
    "x = torch.FloatTensor([1,2,3])\n",
    "x.requires_grad = True\n",
    "print(x, '\\n')\n",
    "out = (x+1).pow(2).t() # 미분함수 f'(x) = 2(x+1)\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "\n",
    "print(f\"First call\\n{x.grad}\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "\n",
    "print(f\"\\nSecond call\\n{x.grad}\")\n",
    "x.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{x.grad}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward 단계에서 detach 이전 layer에는 gradient 계산을 멈춤\n",
    "\n",
    "x = torch.randn(size=(10,)) # 입력변수가 10개인 관측치\n",
    "y = torch.tensor(1.0)\n",
    "\n",
    "w1 = torch.randn(size=(10,5),requires_grad=True)\n",
    "w2 = torch.randn(size=(5,1),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1280], grad_fn=<PowBackward0>)\n",
      "None\n",
      "tensor([[ 0.3105],\n",
      "        [-0.0249],\n",
      "        [-1.0226],\n",
      "        [-0.5425],\n",
      "        [ 0.0593]])\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.matmul((torch.matmul(x,w1)).detach(),w2)\n",
    "\n",
    "loss = (y-y_pred)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(w1.grad)\n",
    "print(w2.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward를 위한 computation graph를 만드는 것은 연산 시간을 늘림\n",
    "# backward가 필요없는 구간에서는 자동 미분을 끄는 용도 (모델 테스트 단계)\n",
    "\n",
    "x = torch.randn(size=(10,)) # 입력변수가 10개인 관측치\n",
    "y = torch.tensor(1.0)\n",
    "\n",
    "w1 = torch.randn(size=(10,5),requires_grad=True)\n",
    "w2 = torch.randn(size=(5,1),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3279])\n",
      "tensor([1.7634])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch.matmul((torch.matmul(x,w1)).detach(),w2)\n",
    "\n",
    "    loss = (y-y_pred)**2\n",
    "\n",
    "print(y_pred)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
